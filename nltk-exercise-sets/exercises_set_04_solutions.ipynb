{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNOzdDO4XkgrG3RCqJNUxkf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/scskalicky/LING-226-vuw/blob/main/nltk-exercise-sets/exercises_set_04_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3iQI5yrnayG"
      },
      "source": [
        "# Exercise set 04\n",
        "\n",
        "This exercise set covers sections 3.6 and 3.7 from Chapter 03 and 4.1 to 4.4 from Ch. 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIKZHsi5nSGU"
      },
      "source": [
        "1. ☼ Define a string `s = 'colorless'`. Write a Python statement that changes this to \"colourless\" using only the slice and concatenation operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPqHuXz1nXP_"
      },
      "source": [
        "s = 'colorless'\n",
        "s1 = s[:4] + 'u' + s[4:]\n",
        "s1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-lxfYZHnnxP"
      },
      "source": [
        "2. ☼ We can use the slice notation to remove morphological endings on words. For example, `'dogs'[:-1]` removes the last character of `dogs`, leaving `dog`. Use slice notation to remove the affixes from these words (we've inserted a hyphen to indicate the affix boundary, but omit this from your strings): dish-es, run-ning, nation-ality, un-do, pre-heat.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0UVvi5nnqGn"
      },
      "source": [
        "print('dishes'[:-2], 'running'[:-4], 'nationality'[:-5], 'preheat'[:-4] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkqoJAfGoAAl"
      },
      "source": [
        "3. ☼ We saw how we can generate an IndexError by indexing beyond the end of a string. Is it possible to construct an index that goes too far to the left, before the start of the string?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ6l5MaOoByo"
      },
      "source": [
        "# yes\n",
        "'string'[-7]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "048uJ4fZogDc"
      },
      "source": [
        "4. ☼ We can specify a \"step\" size for the slice. The following returns every second character within the slice: `monty[6:11:2]`. It also works in the reverse direction: `monty[10:5:-2]` Try these for yourself, then experiment with different step values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWzS2KIroibc"
      },
      "source": [
        "'Soda Onion'[1::2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIOX08oVovfU"
      },
      "source": [
        "5. ☼ What happens if you ask the interpreter to evaluate `monty[::-1]`? Explain why this is a reasonable result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1aXYJ5kowV2"
      },
      "source": [
        "# it is slicing the entire string with a step size of 1 \n",
        "'monty'[::1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0P8M1KC_j07"
      },
      "source": [
        "10. ☼ Rewrite the following loop as a list comprehension:\n",
        "\n",
        " \t\n",
        ">>> `sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']`\n",
        ">>> `result = []`\n",
        ">>> `for word in sent:`\n",
        "...    ` word_len = (word, len(word))`\n",
        "...    ` result.append(word_len)`\n",
        ">>> `result`\n",
        "`[('The', 3), ('dog', 3), ('gave', 4), ('John', 4), ('the', 3), ('newspaper', 9)`]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPkGtWkn7rIS"
      },
      "source": [
        "sent = ['The', 'dog', 'gave', 'John', 'the', 'newspaper']\n",
        "result = []\n",
        "for word in sent:\n",
        "  word_len = (word, len(word))\n",
        "  result.append(word_len)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX20MtsS_wba"
      },
      "source": [
        "# this might show you why list comprehensions can be easier to write efficient\n",
        "[(w, len(w)) for w in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLpV8bVT_46x"
      },
      "source": [
        "11. ☼ Define a string `raw` containing a sentence of your own choosing. Now, split raw on some character other than space, such as 's'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhKrA7As_7ad"
      },
      "source": [
        "raw = 'we live in a society!'\n",
        "\n",
        "raw.split('i')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QNB4nS_ADG9"
      },
      "source": [
        "12. ☼ Write a `for loop` to print out the characters of a string, one per line.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGEt02cEAE67"
      },
      "source": [
        "for i in raw:\n",
        "  print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiQ3Nb97AI2y"
      },
      "source": [
        "13. ☼ What is the difference between calling `split` on a string with no argument or with `' '` as the argument, e.g. `sent.split()` versus `sent.split(' ')`? What happens when the string being split contains tab characters, consecutive space characters, or a sequence of tabs and spaces? (In IDLE you will need to use `'\\t'` to enter a tab character.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9CZtT8QANfW"
      },
      "source": [
        "raw.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2t-acxfAOv0"
      },
      "source": [
        "raw.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tllmM8RqARZY"
      },
      "source": [
        "raw2 = 'we live \\n in a \\n society!'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OALgaekEAZxl"
      },
      "source": [
        "# the point is to show you that the default of split is not just a space, but ANY whitespace char, including tab and line breaks. \n",
        "raw2.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4uLG7FcAcMu"
      },
      "source": [
        "raw2.split(' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2N15cFmAkPv"
      },
      "source": [
        "14. ☼ Create a variable `words` containing a list of words. Experiment with `words.sort()` and `sorted(words)`. What is the difference?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1rXVHybAl7O"
      },
      "source": [
        "some_words = ['the', 'sea', 'was', 'angry', 'that', 'day', 'my', 'friends']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wchdPRh2Ap0m"
      },
      "source": [
        "# .sort changes the list without outputting it - a procedure\n",
        "some_words.sort()\n",
        "\n",
        "some_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FskVEVlQA0y8"
      },
      "source": [
        "# sorted outputs the sorted list without change the list - a function\n",
        "some_words = ['the', 'sea', 'was', 'angry', 'that', 'day', 'my', 'friends']\n",
        "sorted(some_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3p5tyl3UQsC"
      },
      "source": [
        "# some_words doesn't change after sorted() is called on it\n",
        "some_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQPPrTqOVLm5"
      },
      "source": [
        "31. ◑ Define the variable `saying` to contain the list \n",
        "> `['After', 'all', 'is', 'said', 'and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']`. \n",
        "\n",
        "Process this list using a for loop, and store the length of each word in a new list `lengths`. \n",
        "\n",
        "Hint: begin by assigning the empty list to `lengths`, using `lengths = []`. Then each time through the loop, use `append()` to add another length value to the list. Now do the same thing using a list comprehension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2up7G0lYKsO"
      },
      "source": [
        "saying = ['After', 'all', 'is', 'said', 'and', 'done', ',', 'more', 'is', 'said', 'than', 'done', '.']\n",
        "\n",
        "length = []\n",
        "\n",
        "for word in saying:\n",
        "  length.append(len(word))\n",
        "\n",
        "length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaxCAfrfg9tB"
      },
      "source": [
        "# with a list comprehension\n",
        "length = [len(word) for word in saying]\n",
        "\n",
        "length"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWKsAJY5VRs1"
      },
      "source": [
        "32. ◑ Define a variable `silly` to contain the string: `'newly formed bland ideas are inexpressible in an infuriating way'`. (This happens to be the legitimate interpretation that bilingual English-Spanish speakers can assign to Chomsky's famous nonsense phrase, colorless green ideas sleep furiously according to Wikipedia). Now write code to perform the following tasks:\n",
        "\n",
        "> a. Split `silly` into a list of strings, one per word, using Python's `split()` operation, and save this to a variable called `bland`. \\\n",
        "> b. Extract the second letter of each word in `silly` and join them into a string, to get `'eoldrnnnna'`. \\\n",
        "> c. Combine the words in `bland` back into a single string, using `join()`. Make sure the words in the resulting string are separated with whitespace. \\\n",
        "> d. Print the words of `silly` in alphabetical order, one per line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5RYraFHebYt"
      },
      "source": [
        "silly = 'newly formed bland ideas are inexpressible in an infuriating way.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTaCl8Z9el8S"
      },
      "source": [
        "# split silly into strings\n",
        "bland = silly.split()\n",
        "bland"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wi1_xa2ae3xa"
      },
      "source": [
        "# second letter of each word, easier to use bland\n",
        "''.join([i[1] for i in bland])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBgilcNAf0ks"
      },
      "source": [
        "# how to do it from silly\n",
        "''.join([i[1] for i in silly.split()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oJ64EwUf--z"
      },
      "source": [
        "# rejoin the words from bland\n",
        "' '.join(bland)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evS4PHxugHQX"
      },
      "source": [
        "sorted_silly = sorted(silly.split())\n",
        "\n",
        "for word in sorted_silly:\n",
        "  print(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLXtW0e-qCac"
      },
      "source": [
        "These are from Chapter 04"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLQYXfRNYnST"
      },
      "source": [
        "14. ◑ Write a function `novel10(text)` that prints any word that appeared in the last 10% of a text that had not been encountered earlier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd-HKgP2hbxK"
      },
      "source": [
        "# check section 4.1 and 4.2 in chapter 04 for this\n",
        "\n",
        "def novel10(text):\n",
        "  words = text.split()\n",
        "\n",
        "  # int is necessary to remove floating decimal\n",
        "  cut = int(.9 * len(words))\n",
        "\n",
        "  print([word for word in words[cut:] if word not in words[:cut]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DwkDS3FiEEO"
      },
      "source": [
        "novel10(open('/content/drive/MyDrive/texts/mood_ring.txt').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ep7wsnq2YnVH"
      },
      "source": [
        "15. ◑ Write a program that takes a sentence `expressed` as a single string, splits it and counts up the words. Get it to print out each word and the word's frequency, one per line, in alphabetical order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngWGHU6iqwhK"
      },
      "source": [
        "import nltk\n",
        "from nltk import FreqDist, word_tokenize\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av9VvcKvtdbD"
      },
      "source": [
        "def frequency(expressed):\n",
        "  assert isinstance(expressed, str), 'please input a string'\n",
        "\n",
        "  # you will get better results using the NLTK tokenizer compared to .split()\n",
        "  words = word_tokenize(expressed.lower())\n",
        "  \n",
        "  # we can also use the NLTK freq dist instead of using something like .count\n",
        "  words_fd = FreqDist(words)\n",
        "\n",
        "  # instead of looping through fdist\n",
        "  # we can loop through words and call their values from the fdist \n",
        "  for word in sorted(set(words)):\n",
        "    print(word, ':', words_fd[word])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM5BkK0KsFue"
      },
      "source": [
        "frequency(open('/content/drive/MyDrive/texts/mood_ring.txt').read())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bu2rhJdwZUeZ"
      },
      "source": [
        "17. ◑ Write a function `shorten(text, n)` to process a text, omitting the n most frequently occurring words of the text. How readable is it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmMbYbkCr1Sf"
      },
      "source": [
        "def shorten(text, n):\n",
        "  assert isinstance(text, str), 'pease input a string'\n",
        "\n",
        "  words = word_tokenize(text.lower())\n",
        "\n",
        "  words_fd = FreqDist(words)\n",
        "\n",
        "  new_text = []\n",
        "\n",
        "  for word in words:\n",
        "    if words_fd[word] <= n:\n",
        "      new_text.append(word)\n",
        "\n",
        "  new_text_joined = ' '.join(new_text)\n",
        "  \n",
        "  return new_text_joined\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU4pziWfuVEy"
      },
      "source": [
        "# pretty funny if you delete any repeated word.\n",
        "shorten(open('/content/drive/MyDrive/texts/marine_biologist.txt').read(), 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3NxuyWju0Ig"
      },
      "source": [
        "shorten(open('/content/drive/MyDrive/texts/marine_biologist.txt').read(), 5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
